{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcd9864b",
   "metadata": {},
   "source": [
    "# Question 2: Resampling and Frequency Conversion\n",
    "\n",
    "This question focuses on resampling operations and frequency conversion using ICU monitoring data (hourly) and patient vital signs data (daily).\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d645281",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs('output', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a454b02",
   "metadata": {},
   "source": [
    "## Part 2.1: Load and Prepare Data\n",
    "\n",
    "**Note:** These datasets have realistic characteristics:\n",
    "- **ICU Monitoring**: 75 patients with variable stay lengths (2-30 days). Not all patients are present for the entire 6-month period - patients are admitted and discharged at different times.\n",
    "- **Patient Vitals**: Already contains some missing visits (~5% missing data). This is realistic and will be useful for practicing missing data handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b166d302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICU monitoring shape: (86400, 7)\n",
      "Patient vitals shape: (18250, 7)\n",
      "\n",
      "ICU monitoring sample:\n",
      "                    patient_id  heart_rate  blood_pressure_systolic  \\\n",
      "datetime                                                              \n",
      "2023-01-01 00:00:00     ICU001   82.000000                      126   \n",
      "2023-01-01 01:00:00     ICU001   98.294095                      128   \n",
      "2023-01-01 02:00:00     ICU001  103.500000                      129   \n",
      "2023-01-01 03:00:00     ICU001   91.535534                      136   \n",
      "2023-01-01 04:00:00     ICU001   87.330127                      129   \n",
      "\n",
      "                     blood_pressure_diastolic  oxygen_saturation  temperature  \n",
      "datetime                                                                       \n",
      "2023-01-01 00:00:00                        65                 96    98.783988  \n",
      "2023-01-01 01:00:00                        67                 95    99.186212  \n",
      "2023-01-01 02:00:00                        68                 94    98.800638  \n",
      "2023-01-01 03:00:00                        75                 96    98.349004  \n",
      "2023-01-01 04:00:00                        68                 95    98.643958  \n",
      "\n",
      "Patient vitals sample:\n",
      "           patient_id  temperature  heart_rate  blood_pressure_systolic  \\\n",
      "date                                                                      \n",
      "2023-01-01      P0001    98.389672          71                      119   \n",
      "2023-01-02      P0001    98.492046          67                      117   \n",
      "2023-01-03      P0001    98.790163          70                      113   \n",
      "2023-01-04      P0001    98.635781          74                      117   \n",
      "2023-01-05      P0001    98.051660          67                      118   \n",
      "\n",
      "            blood_pressure_diastolic     weight  \n",
      "date                                             \n",
      "2023-01-01                        84  68.996865  \n",
      "2023-01-02                        82  67.720215  \n",
      "2023-01-03                        78  67.846825  \n",
      "2023-01-04                        82  67.693993  \n",
      "2023-01-05                        83  68.228852  \n",
      "\n",
      "ICU patients: 20\n",
      "ICU date range: 2023-01-01 00:00:00 to 2023-06-29 23:00:00\n",
      "\n",
      "Patient vitals patients: 50\n",
      "Patient vitals date range: 2023-01-01 00:00:00 to 2023-12-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Load ICU monitoring data (hourly)\n",
    "icu_monitoring = pd.read_csv('data/icu_monitoring.csv')\n",
    "\n",
    "# Load patient vitals data (daily) - for comparison\n",
    "patient_vitals = pd.read_csv('data/patient_vitals.csv')\n",
    "\n",
    "print(\"ICU monitoring shape:\", icu_monitoring.shape)\n",
    "print(\"Patient vitals shape:\", patient_vitals.shape)\n",
    "\n",
    "# Convert datetime columns and set as index\n",
    "icu_monitoring['datetime'] = pd.to_datetime(icu_monitoring['datetime'])\n",
    "icu_monitoring = icu_monitoring.set_index('datetime')\n",
    "\n",
    "patient_vitals['date'] = pd.to_datetime(patient_vitals['date'])\n",
    "patient_vitals = patient_vitals.set_index('date')\n",
    "\n",
    "print(\"\\nICU monitoring sample:\")\n",
    "print(icu_monitoring.head())\n",
    "print(\"\\nPatient vitals sample:\")\n",
    "print(patient_vitals.head())\n",
    "\n",
    "# Check data characteristics\n",
    "print(f\"\\nICU patients: {icu_monitoring['patient_id'].nunique()}\")\n",
    "print(f\"ICU date range: {icu_monitoring.index.min()} to {icu_monitoring.index.max()}\")\n",
    "print(f\"\\nPatient vitals patients: {patient_vitals['patient_id'].nunique()}\")\n",
    "print(f\"Patient vitals date range: {patient_vitals.index.min()} to {patient_vitals.index.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca7dd39",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Part 2.2: Time Series Selection\n",
    "\n",
    "**‚ö†Ô∏è WARNING: Sort Index Before Date Selection!**\n",
    "Since multiple patients share the same date, the `patient_vitals` index is non-monotonic (not strictly increasing). **You MUST sort the index first** before using `.loc` with date ranges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f905616",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "patient_vitals = patient_vitals.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551db0cf",
   "metadata": {},
   "source": [
    "Without sorting, pandas cannot reliably handle date range selections and may return unexpected results or errors.\n",
    "\n",
    "**TODO: Perform time series indexing and selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f8e2fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "January 1, 2023 data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>temperature</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>blood_pressure_systolic</th>\n",
       "      <th>blood_pressure_diastolic</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>P0001</td>\n",
       "      <td>98.389672</td>\n",
       "      <td>71</td>\n",
       "      <td>119</td>\n",
       "      <td>84</td>\n",
       "      <td>68.996865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>P0024</td>\n",
       "      <td>97.552103</td>\n",
       "      <td>71</td>\n",
       "      <td>111</td>\n",
       "      <td>70</td>\n",
       "      <td>49.386068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>P0025</td>\n",
       "      <td>98.806201</td>\n",
       "      <td>83</td>\n",
       "      <td>118</td>\n",
       "      <td>65</td>\n",
       "      <td>84.096164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>P0047</td>\n",
       "      <td>98.943464</td>\n",
       "      <td>63</td>\n",
       "      <td>110</td>\n",
       "      <td>76</td>\n",
       "      <td>54.318578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>P0026</td>\n",
       "      <td>98.758551</td>\n",
       "      <td>75</td>\n",
       "      <td>114</td>\n",
       "      <td>75</td>\n",
       "      <td>49.830300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>P0027</td>\n",
       "      <td>98.462467</td>\n",
       "      <td>90</td>\n",
       "      <td>119</td>\n",
       "      <td>74</td>\n",
       "      <td>72.943755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>P0028</td>\n",
       "      <td>99.632166</td>\n",
       "      <td>71</td>\n",
       "      <td>117</td>\n",
       "      <td>86</td>\n",
       "      <td>104.977255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>P0029</td>\n",
       "      <td>98.881121</td>\n",
       "      <td>68</td>\n",
       "      <td>121</td>\n",
       "      <td>71</td>\n",
       "      <td>59.883550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>P0030</td>\n",
       "      <td>98.403614</td>\n",
       "      <td>73</td>\n",
       "      <td>122</td>\n",
       "      <td>79</td>\n",
       "      <td>60.754351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>P0031</td>\n",
       "      <td>98.410626</td>\n",
       "      <td>63</td>\n",
       "      <td>113</td>\n",
       "      <td>75</td>\n",
       "      <td>72.486551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>P0046</td>\n",
       "      <td>98.507553</td>\n",
       "      <td>89</td>\n",
       "      <td>123</td>\n",
       "      <td>66</td>\n",
       "      <td>62.109514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>P0032</td>\n",
       "      <td>99.547822</td>\n",
       "      <td>70</td>\n",
       "      <td>123</td>\n",
       "      <td>72</td>\n",
       "      <td>74.585881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>P0033</td>\n",
       "      <td>97.612817</td>\n",
       "      <td>56</td>\n",
       "      <td>112</td>\n",
       "      <td>73</td>\n",
       "      <td>51.137556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>P0034</td>\n",
       "      <td>99.075484</td>\n",
       "      <td>88</td>\n",
       "      <td>124</td>\n",
       "      <td>76</td>\n",
       "      <td>66.779965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>P0035</td>\n",
       "      <td>98.968285</td>\n",
       "      <td>62</td>\n",
       "      <td>116</td>\n",
       "      <td>79</td>\n",
       "      <td>76.864597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>P0036</td>\n",
       "      <td>99.589629</td>\n",
       "      <td>85</td>\n",
       "      <td>119</td>\n",
       "      <td>76</td>\n",
       "      <td>81.704275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>P0037</td>\n",
       "      <td>98.557134</td>\n",
       "      <td>64</td>\n",
       "      <td>117</td>\n",
       "      <td>84</td>\n",
       "      <td>78.116801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>P0038</td>\n",
       "      <td>98.137036</td>\n",
       "      <td>62</td>\n",
       "      <td>129</td>\n",
       "      <td>85</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>P0045</td>\n",
       "      <td>98.265412</td>\n",
       "      <td>67</td>\n",
       "      <td>119</td>\n",
       "      <td>73</td>\n",
       "      <td>76.812239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>P0039</td>\n",
       "      <td>98.746267</td>\n",
       "      <td>88</td>\n",
       "      <td>128</td>\n",
       "      <td>77</td>\n",
       "      <td>59.093381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>P0023</td>\n",
       "      <td>99.142508</td>\n",
       "      <td>65</td>\n",
       "      <td>118</td>\n",
       "      <td>83</td>\n",
       "      <td>49.643152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>P0022</td>\n",
       "      <td>97.700397</td>\n",
       "      <td>68</td>\n",
       "      <td>122</td>\n",
       "      <td>79</td>\n",
       "      <td>68.067771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>P0021</td>\n",
       "      <td>99.549514</td>\n",
       "      <td>81</td>\n",
       "      <td>125</td>\n",
       "      <td>73</td>\n",
       "      <td>77.967356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>P0020</td>\n",
       "      <td>98.572122</td>\n",
       "      <td>64</td>\n",
       "      <td>113</td>\n",
       "      <td>77</td>\n",
       "      <td>70.714935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>P0004</td>\n",
       "      <td>99.214044</td>\n",
       "      <td>73</td>\n",
       "      <td>126</td>\n",
       "      <td>82</td>\n",
       "      <td>93.836456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>P0005</td>\n",
       "      <td>98.075744</td>\n",
       "      <td>61</td>\n",
       "      <td>119</td>\n",
       "      <td>86</td>\n",
       "      <td>86.238145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>P0006</td>\n",
       "      <td>98.373337</td>\n",
       "      <td>69</td>\n",
       "      <td>113</td>\n",
       "      <td>81</td>\n",
       "      <td>52.923008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>P0007</td>\n",
       "      <td>99.005033</td>\n",
       "      <td>81</td>\n",
       "      <td>131</td>\n",
       "      <td>75</td>\n",
       "      <td>56.926071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>P0050</td>\n",
       "      <td>99.008145</td>\n",
       "      <td>74</td>\n",
       "      <td>130</td>\n",
       "      <td>81</td>\n",
       "      <td>75.383257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>P0008</td>\n",
       "      <td>97.987253</td>\n",
       "      <td>82</td>\n",
       "      <td>111</td>\n",
       "      <td>68</td>\n",
       "      <td>68.629172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>P0009</td>\n",
       "      <td>99.368380</td>\n",
       "      <td>90</td>\n",
       "      <td>128</td>\n",
       "      <td>70</td>\n",
       "      <td>62.387123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>P0010</td>\n",
       "      <td>99.244181</td>\n",
       "      <td>86</td>\n",
       "      <td>123</td>\n",
       "      <td>77</td>\n",
       "      <td>59.678637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>P0011</td>\n",
       "      <td>98.829135</td>\n",
       "      <td>81</td>\n",
       "      <td>124</td>\n",
       "      <td>80</td>\n",
       "      <td>60.073705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>P0040</td>\n",
       "      <td>99.024034</td>\n",
       "      <td>77</td>\n",
       "      <td>123</td>\n",
       "      <td>77</td>\n",
       "      <td>79.612071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>P0012</td>\n",
       "      <td>97.820562</td>\n",
       "      <td>64</td>\n",
       "      <td>121</td>\n",
       "      <td>71</td>\n",
       "      <td>48.410507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>P0049</td>\n",
       "      <td>98.124573</td>\n",
       "      <td>66</td>\n",
       "      <td>120</td>\n",
       "      <td>73</td>\n",
       "      <td>48.085497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>P0014</td>\n",
       "      <td>98.405814</td>\n",
       "      <td>76</td>\n",
       "      <td>121</td>\n",
       "      <td>75</td>\n",
       "      <td>82.570817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>P0015</td>\n",
       "      <td>99.039286</td>\n",
       "      <td>81</td>\n",
       "      <td>112</td>\n",
       "      <td>72</td>\n",
       "      <td>65.294840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>P0016</td>\n",
       "      <td>99.201435</td>\n",
       "      <td>66</td>\n",
       "      <td>115</td>\n",
       "      <td>82</td>\n",
       "      <td>82.512213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>P0002</td>\n",
       "      <td>98.432983</td>\n",
       "      <td>87</td>\n",
       "      <td>114</td>\n",
       "      <td>74</td>\n",
       "      <td>58.179729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>P0017</td>\n",
       "      <td>99.146657</td>\n",
       "      <td>87</td>\n",
       "      <td>115</td>\n",
       "      <td>84</td>\n",
       "      <td>81.641348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>P0018</td>\n",
       "      <td>97.867184</td>\n",
       "      <td>87</td>\n",
       "      <td>125</td>\n",
       "      <td>86</td>\n",
       "      <td>67.832031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>P0019</td>\n",
       "      <td>99.026862</td>\n",
       "      <td>81</td>\n",
       "      <td>123</td>\n",
       "      <td>73</td>\n",
       "      <td>70.635756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>P0048</td>\n",
       "      <td>98.519258</td>\n",
       "      <td>75</td>\n",
       "      <td>118</td>\n",
       "      <td>80</td>\n",
       "      <td>63.274809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>P0013</td>\n",
       "      <td>98.662933</td>\n",
       "      <td>69</td>\n",
       "      <td>110</td>\n",
       "      <td>81</td>\n",
       "      <td>57.631518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>P0041</td>\n",
       "      <td>98.452086</td>\n",
       "      <td>84</td>\n",
       "      <td>131</td>\n",
       "      <td>84</td>\n",
       "      <td>49.964682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>P0003</td>\n",
       "      <td>98.167264</td>\n",
       "      <td>83</td>\n",
       "      <td>110</td>\n",
       "      <td>70</td>\n",
       "      <td>79.302945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>P0043</td>\n",
       "      <td>98.958357</td>\n",
       "      <td>79</td>\n",
       "      <td>113</td>\n",
       "      <td>75</td>\n",
       "      <td>65.165670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>P0042</td>\n",
       "      <td>98.881607</td>\n",
       "      <td>78</td>\n",
       "      <td>120</td>\n",
       "      <td>72</td>\n",
       "      <td>58.710525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>P0044</td>\n",
       "      <td>98.345119</td>\n",
       "      <td>66</td>\n",
       "      <td>114</td>\n",
       "      <td>69</td>\n",
       "      <td>72.543359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           patient_id  temperature  heart_rate  blood_pressure_systolic  \\\n",
       "date                                                                      \n",
       "2023-01-01      P0001    98.389672          71                      119   \n",
       "2023-01-01      P0024    97.552103          71                      111   \n",
       "2023-01-01      P0025    98.806201          83                      118   \n",
       "2023-01-01      P0047    98.943464          63                      110   \n",
       "2023-01-01      P0026    98.758551          75                      114   \n",
       "2023-01-01      P0027    98.462467          90                      119   \n",
       "2023-01-01      P0028    99.632166          71                      117   \n",
       "2023-01-01      P0029    98.881121          68                      121   \n",
       "2023-01-01      P0030    98.403614          73                      122   \n",
       "2023-01-01      P0031    98.410626          63                      113   \n",
       "2023-01-01      P0046    98.507553          89                      123   \n",
       "2023-01-01      P0032    99.547822          70                      123   \n",
       "2023-01-01      P0033    97.612817          56                      112   \n",
       "2023-01-01      P0034    99.075484          88                      124   \n",
       "2023-01-01      P0035    98.968285          62                      116   \n",
       "2023-01-01      P0036    99.589629          85                      119   \n",
       "2023-01-01      P0037    98.557134          64                      117   \n",
       "2023-01-01      P0038    98.137036          62                      129   \n",
       "2023-01-01      P0045    98.265412          67                      119   \n",
       "2023-01-01      P0039    98.746267          88                      128   \n",
       "2023-01-01      P0023    99.142508          65                      118   \n",
       "2023-01-01      P0022    97.700397          68                      122   \n",
       "2023-01-01      P0021    99.549514          81                      125   \n",
       "2023-01-01      P0020    98.572122          64                      113   \n",
       "2023-01-01      P0004    99.214044          73                      126   \n",
       "2023-01-01      P0005    98.075744          61                      119   \n",
       "2023-01-01      P0006    98.373337          69                      113   \n",
       "2023-01-01      P0007    99.005033          81                      131   \n",
       "2023-01-01      P0050    99.008145          74                      130   \n",
       "2023-01-01      P0008    97.987253          82                      111   \n",
       "2023-01-01      P0009    99.368380          90                      128   \n",
       "2023-01-01      P0010    99.244181          86                      123   \n",
       "2023-01-01      P0011    98.829135          81                      124   \n",
       "2023-01-01      P0040    99.024034          77                      123   \n",
       "2023-01-01      P0012    97.820562          64                      121   \n",
       "2023-01-01      P0049    98.124573          66                      120   \n",
       "2023-01-01      P0014    98.405814          76                      121   \n",
       "2023-01-01      P0015    99.039286          81                      112   \n",
       "2023-01-01      P0016    99.201435          66                      115   \n",
       "2023-01-01      P0002    98.432983          87                      114   \n",
       "2023-01-01      P0017    99.146657          87                      115   \n",
       "2023-01-01      P0018    97.867184          87                      125   \n",
       "2023-01-01      P0019    99.026862          81                      123   \n",
       "2023-01-01      P0048    98.519258          75                      118   \n",
       "2023-01-01      P0013    98.662933          69                      110   \n",
       "2023-01-01      P0041    98.452086          84                      131   \n",
       "2023-01-01      P0003    98.167264          83                      110   \n",
       "2023-01-01      P0043    98.958357          79                      113   \n",
       "2023-01-01      P0042    98.881607          78                      120   \n",
       "2023-01-01      P0044    98.345119          66                      114   \n",
       "\n",
       "            blood_pressure_diastolic      weight  \n",
       "date                                              \n",
       "2023-01-01                        84   68.996865  \n",
       "2023-01-01                        70   49.386068  \n",
       "2023-01-01                        65   84.096164  \n",
       "2023-01-01                        76   54.318578  \n",
       "2023-01-01                        75   49.830300  \n",
       "2023-01-01                        74   72.943755  \n",
       "2023-01-01                        86  104.977255  \n",
       "2023-01-01                        71   59.883550  \n",
       "2023-01-01                        79   60.754351  \n",
       "2023-01-01                        75   72.486551  \n",
       "2023-01-01                        66   62.109514  \n",
       "2023-01-01                        72   74.585881  \n",
       "2023-01-01                        73   51.137556  \n",
       "2023-01-01                        76   66.779965  \n",
       "2023-01-01                        79   76.864597  \n",
       "2023-01-01                        76   81.704275  \n",
       "2023-01-01                        84   78.116801  \n",
       "2023-01-01                        85   40.000000  \n",
       "2023-01-01                        73   76.812239  \n",
       "2023-01-01                        77   59.093381  \n",
       "2023-01-01                        83   49.643152  \n",
       "2023-01-01                        79   68.067771  \n",
       "2023-01-01                        73   77.967356  \n",
       "2023-01-01                        77   70.714935  \n",
       "2023-01-01                        82   93.836456  \n",
       "2023-01-01                        86   86.238145  \n",
       "2023-01-01                        81   52.923008  \n",
       "2023-01-01                        75   56.926071  \n",
       "2023-01-01                        81   75.383257  \n",
       "2023-01-01                        68   68.629172  \n",
       "2023-01-01                        70   62.387123  \n",
       "2023-01-01                        77   59.678637  \n",
       "2023-01-01                        80   60.073705  \n",
       "2023-01-01                        77   79.612071  \n",
       "2023-01-01                        71   48.410507  \n",
       "2023-01-01                        73   48.085497  \n",
       "2023-01-01                        75   82.570817  \n",
       "2023-01-01                        72   65.294840  \n",
       "2023-01-01                        82   82.512213  \n",
       "2023-01-01                        74   58.179729  \n",
       "2023-01-01                        84   81.641348  \n",
       "2023-01-01                        86   67.832031  \n",
       "2023-01-01                        73   70.635756  \n",
       "2023-01-01                        80   63.274809  \n",
       "2023-01-01                        81   57.631518  \n",
       "2023-01-01                        84   49.964682  \n",
       "2023-01-01                        70   79.302945  \n",
       "2023-01-01                        75   65.165670  \n",
       "2023-01-01                        72   58.710525  \n",
       "2023-01-01                        69   72.543359  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records on Jan 1: 50 (some patients may start later)\n",
      "January 2023 shape: (1550, 6)\n",
      "\n",
      "First quarter average temperature: 98.97¬∞F\n",
      "After June average temperature: 98.41¬∞F\n",
      "First week average temperature: 98.68¬∞F\n",
      "Last week average temperature: 98.65¬∞F\n",
      "\n",
      "Business hours data shape: (32400, 6)\n",
      "\n",
      "Average heart rate - All hours: 81.7 bpm\n",
      "Average heart rate - Business hours: 80.7 bpm\n",
      "Average temperature - All hours: 98.5¬∞F\n",
      "Average temperature - Business hours: 98.5¬∞F\n"
     ]
    }
   ],
   "source": [
    "# 1. Select data by specific dates\n",
    "# ==============================\n",
    "\n",
    "# January 1, 2023\n",
    "january_first = patient_vitals.loc[\"2023-01-01\"]\n",
    "\n",
    "print(\"January 1, 2023 data:\")\n",
    "display(january_first)\n",
    "print(f\"Records on Jan 1: {len(january_first)} (some patients may start later)\")\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 2. Select data by date ranges\n",
    "# ==============================\n",
    "\n",
    "# Entire January 2023\n",
    "january_data = patient_vitals.loc[\"2023-01-01\" : \"2023-01-31\"]\n",
    "\n",
    "print(\"January 2023 shape:\", january_data.shape)\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 3. Select data by time periods\n",
    "# ==============================\n",
    "\n",
    "# First quarter\n",
    "first_quarter = patient_vitals.loc[\"2023-01-01\" : \"2023-03-31\"]\n",
    "\n",
    "# Entire 2023\n",
    "entire_year = patient_vitals.loc[\"2023\"]  # shorthand for 2023-01-01 ‚Üí 2023-12-31\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 4. Select first and last week\n",
    "# ==============================\n",
    "\n",
    "first_week = patient_vitals.loc[: patient_vitals.index.min() + pd.Timedelta(days=6)]\n",
    "last_week = patient_vitals.loc[patient_vitals.index.max() - pd.Timedelta(days=6) :]\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 5. Using truncate()\n",
    "# ==============================\n",
    "\n",
    "# Data after June 1, 2023\n",
    "data_after_june = patient_vitals.truncate(before=\"2023-06-01\")\n",
    "\n",
    "# Data before September 1, 2023\n",
    "data_before_september = patient_vitals.truncate(after=\"2023-08-31\")\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 6. Summary analysis\n",
    "# ==============================\n",
    "\n",
    "print(f\"\\nFirst quarter average temperature: {first_quarter['temperature'].mean():.2f}¬∞F\")\n",
    "print(f\"After June average temperature: {data_after_june['temperature'].mean():.2f}¬∞F\")\n",
    "print(f\"First week average temperature: {first_week['temperature'].mean():.2f}¬∞F\")\n",
    "print(f\"Last week average temperature: {last_week['temperature'].mean():.2f}¬∞F\")\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 7. ICU data ‚Äî time-of-day filtering\n",
    "# ==============================\n",
    "\n",
    "# Business hours 9 AM to 5 PM\n",
    "business_hours = icu_monitoring.between_time(\"09:00\", \"17:00\")\n",
    "\n",
    "print(\"\\nBusiness hours data shape:\", business_hours.shape)\n",
    "\n",
    "# Noon-only readings\n",
    "noon_data = icu_monitoring.at_time(\"12:00\")\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 8. Compare business vs all hours\n",
    "# ==============================\n",
    "\n",
    "all_hours_avg = icu_monitoring.select_dtypes(include=[np.number]).mean()\n",
    "business_hours_avg = business_hours.select_dtypes(include=[np.number]).mean()\n",
    "\n",
    "print(f\"\\nAverage heart rate - All hours: {all_hours_avg['heart_rate']:.1f} bpm\")\n",
    "print(f\"Average heart rate - Business hours: {business_hours_avg['heart_rate']:.1f} bpm\")\n",
    "\n",
    "print(f\"Average temperature - All hours: {all_hours_avg['temperature']:.1f}¬∞F\")\n",
    "print(f\"Average temperature - Business hours: {business_hours_avg['temperature']:.1f}¬∞F\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4653f2fe",
   "metadata": {},
   "source": [
    "## Part 2.3: Resampling Operations\n",
    "\n",
    "**TODO: Perform resampling and frequency conversion**\n",
    "\n",
    "**Important Note:** When resampling DataFrames that contain non-numeric columns (like `patient_id`), you'll get an error if you try to aggregate them with numeric functions like `mean()`. Use `df.select_dtypes(include=[np.number])` to select only numeric columns before resampling, or specify which columns to aggregate in `.agg()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d18466a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICU daily shape: (180, 5)\n",
      "Weekly resampled shape: (53, 5)\n",
      "Monthly resampled shape: (12, 5)\n",
      "Missing values after upsampling:\n",
      "temperature                 323\n",
      "heart_rate                  323\n",
      "blood_pressure_systolic     323\n",
      "blood_pressure_diastolic    323\n",
      "weight                      323\n",
      "dtype: int64\n",
      "\n",
      "Resampling comparison:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "      <th>date_range</th>\n",
       "      <th>row_count</th>\n",
       "      <th>mean_temperature</th>\n",
       "      <th>std_temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>daily</td>\n",
       "      <td>2023-01-01 ‚Üí 2023-12-31</td>\n",
       "      <td>365</td>\n",
       "      <td>98.660538</td>\n",
       "      <td>0.360322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>weekly</td>\n",
       "      <td>2023-01-01 ‚Üí 2023-12-31</td>\n",
       "      <td>53</td>\n",
       "      <td>98.660657</td>\n",
       "      <td>0.358014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>monthly</td>\n",
       "      <td>2023-01-31 ‚Üí 2023-12-31</td>\n",
       "      <td>12</td>\n",
       "      <td>98.662794</td>\n",
       "      <td>0.369503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  frequency               date_range  row_count  mean_temperature  \\\n",
       "0     daily  2023-01-01 ‚Üí 2023-12-31        365         98.660538   \n",
       "1    weekly  2023-01-01 ‚Üí 2023-12-31         53         98.660657   \n",
       "2   monthly  2023-01-31 ‚Üí 2023-12-31         12         98.662794   \n",
       "\n",
       "   std_temperature  \n",
       "0         0.360322  \n",
       "1         0.358014  \n",
       "2         0.369503  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: output/q2_resampling_analysis.csv\n"
     ]
    }
   ],
   "source": [
    "# 1. ICU hourly ‚Üí daily\n",
    "\n",
    "\n",
    "# Select numeric columns only\n",
    "numeric_cols_icu = icu_monitoring.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "icu_daily = icu_monitoring[numeric_cols_icu].resample(\"D\").mean()\n",
    "print(\"ICU daily shape:\", icu_daily.shape)\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 2. Patient vitals daily ‚Üí weekly\n",
    "# ==============================\n",
    "\n",
    "numeric_cols_pv = patient_vitals.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "patient_vitals_weekly = patient_vitals[numeric_cols_pv].resample(\"W\").mean()\n",
    "print(\"Weekly resampled shape:\", patient_vitals_weekly.shape)\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 3. Patient vitals daily ‚Üí monthly\n",
    "# ==============================\n",
    "\n",
    "patient_vitals_monthly = patient_vitals[numeric_cols_pv].resample(\"ME\").mean()\n",
    "print(\"Monthly resampled shape:\", patient_vitals_monthly.shape)\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 4. Different aggregation functions\n",
    "# ==============================\n",
    "\n",
    "icu_daily_stats = icu_monitoring[numeric_cols_icu].resample(\"D\").agg({\n",
    "    \"heart_rate\": [\"mean\", \"max\", \"min\"],\n",
    "    \"temperature\": [\"mean\", \"max\", \"min\"],\n",
    "    \"oxygen_saturation\": \"mean\"\n",
    "})\n",
    "\n",
    "icu_daily_stats.head()\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 5. Upsampling ‚Üí creates missing values\n",
    "# ==============================\n",
    "\n",
    "# Upsample monthly ‚Üí daily (creates NaNs)\n",
    "monthly_to_daily = patient_vitals_monthly.resample(\"D\").asfreq()\n",
    "\n",
    "print(\"Missing values after upsampling:\")\n",
    "print(monthly_to_daily.isna().sum())\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 6. Compare daily vs weekly vs monthly\n",
    "# ==============================\n",
    "\n",
    "# Step 1 ‚Äî aggregate patient_vitals to daily level (mean across patients)\n",
    "patient_vitals_reset = patient_vitals[numeric_cols_pv].reset_index()\n",
    "patient_vitals_daily_agg = patient_vitals_reset.groupby(\"date\").mean()\n",
    "\n",
    "# Ensure datetime is index\n",
    "patient_vitals_daily_agg.index = pd.to_datetime(patient_vitals_daily_agg.index)\n",
    "\n",
    "# Step 2 ‚Äî build summary comparison table\n",
    "resampling_comparison = pd.DataFrame({\n",
    "    \"frequency\": [\"daily\", \"weekly\", \"monthly\"],\n",
    "    \"date_range\": [\n",
    "        f\"{patient_vitals_daily_agg.index.min().date()} ‚Üí {patient_vitals_daily_agg.index.max().date()}\",\n",
    "        f\"{patient_vitals_weekly.index.min().date()} ‚Üí {patient_vitals_weekly.index.max().date()}\",\n",
    "        f\"{patient_vitals_monthly.index.min().date()} ‚Üí {patient_vitals_monthly.index.max().date()}\"\n",
    "    ],\n",
    "    \"row_count\": [\n",
    "        len(patient_vitals_daily_agg),\n",
    "        len(patient_vitals_weekly),\n",
    "        len(patient_vitals_monthly)\n",
    "    ],\n",
    "    \"mean_temperature\": [\n",
    "        patient_vitals_daily_agg[\"temperature\"].mean(),\n",
    "        patient_vitals_weekly[\"temperature\"].mean(),\n",
    "        patient_vitals_monthly[\"temperature\"].mean()\n",
    "    ],\n",
    "    \"std_temperature\": [\n",
    "        patient_vitals_daily_agg[\"temperature\"].std(),\n",
    "        patient_vitals_weekly[\"temperature\"].std(),\n",
    "        patient_vitals_monthly[\"temperature\"].std()\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\nResampling comparison:\")\n",
    "display(resampling_comparison)\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 7. Save output\n",
    "# ==============================\n",
    "\n",
    "resampling_comparison.to_csv(\"output/q2_resampling_analysis.csv\", index=False)\n",
    "print(\"Saved: output/q2_resampling_analysis.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3605486d",
   "metadata": {},
   "source": [
    "## Part 2.4: Missing Data Handling\n",
    "\n",
    "**üí° TIP: High Percentage of Missing Data is Expected!**\n",
    "When upsampling from monthly to daily frequency, you'll create approximately 96% missing data (only 12 month-end dates have values out of 365 days). This is normal and expected for upsampling - don't be alarmed!\n",
    "\n",
    "**Approach:** Create missing values by upsampling monthly data to daily frequency. This creates a clear, structured pattern of missing data that's ideal for practicing imputation methods.\n",
    "\n",
    "**TODO: Handle missing data in time series**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9dd87022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing value count: 323\n",
      "Missing value percentage: 96.41791044776119\n",
      "After forward fill ‚Äî missing values: 0\n",
      "After backward fill ‚Äî missing values: 0\n",
      "Missing after generic interpolate(): 0\n",
      "Missing after linear interpolation: 0\n",
      "Missing after time interpolation: 0\n",
      "Missing after rolling mean imputation: 0\n",
      "Saved: output/q2_missing_data_report.txt\n"
     ]
    }
   ],
   "source": [
    "monthly_temp = patient_vitals_monthly[\"temperature\"]\n",
    "\n",
    "# Upsample to daily frequency ‚Üí creates missing values (only month-end dates have data)\n",
    "ts_with_missing = monthly_temp.resample(\"D\").asfreq()\n",
    "\n",
    "print(\"Missing value count:\", ts_with_missing.isna().sum())\n",
    "print(\"Missing value percentage:\", ts_with_missing.isna().sum() / len(ts_with_missing) * 100)\n",
    "\n",
    "# Forward fill (propagate last known monthly value forward)\n",
    "ts_ffill = ts_with_missing.ffill()\n",
    "\n",
    "# Backward fill (propagate next known monthly value backward)\n",
    "ts_bfill = ts_with_missing.bfill()\n",
    "\n",
    "print(\"After forward fill ‚Äî missing values:\", ts_ffill.isna().sum())\n",
    "print(\"After backward fill ‚Äî missing values:\", ts_bfill.isna().sum())\n",
    "\n",
    "# TODO: Use interpolation methods\n",
    "# Generic interpolate() ‚Äì defaults to linear for numeric series\n",
    "ts_interpolated = ts_with_missing.interpolate()\n",
    "\n",
    "# Explicit linear interpolation\n",
    "ts_interpolated_linear = ts_with_missing.interpolate(method=\"linear\")\n",
    "\n",
    "# Time-based interpolation (uses actual date spacing)\n",
    "ts_interpolated_time = ts_with_missing.interpolate(method=\"time\")\n",
    "\n",
    "print(\"Missing after generic interpolate():\", ts_interpolated.isna().sum())\n",
    "print(\"Missing after linear interpolation:\", ts_interpolated_linear.isna().sum())\n",
    "print(\"Missing after time interpolation:\", ts_interpolated_time.isna().sum())\n",
    "\n",
    "# TODO: Use rolling mean for imputation\n",
    "ts_filled = ts_with_missing.ffill()\n",
    "rolling_mean = ts_filled.rolling(window=7, min_periods=1).mean()\n",
    "ts_rolling_imputed = ts_with_missing.fillna(rolling_mean)\n",
    "print(\"Missing after rolling mean imputation:\", ts_rolling_imputed.isna().sum())\n",
    "\n",
    "\n",
    "missing_by_month = ts_with_missing.groupby(ts_with_missing.index.month).apply(lambda x: x.isna().sum())\n",
    "missing_by_day = ts_with_missing.groupby(ts_with_missing.index.dayofweek).apply(lambda x: x.isna().sum())\n",
    "\n",
    "missing_patterns = f\"Missing by month:\\n{missing_by_month}\\n\\nMissing by day of week:\\n{missing_by_day}\"\n",
    "\n",
    "# 2. Create full 300+ word report\n",
    "missing_data_report = f\"\"\"\n",
    "MISSING DATA REPORT ‚Äî TIME SERIES (Q2.4)\n",
    "\n",
    "1. Missing Value Summary\n",
    "The upsampled daily time series created from monthly temperature data contained a very high rate of missing values. \n",
    "After resampling from month-end data to daily frequency using `.resample('D').asfreq()`, the resulting series had \n",
    "{ts_with_missing.isna().sum()} missing values out of {len(ts_with_missing)} total observations, which is approximately \n",
    "{ts_with_missing.isna().sum() / len(ts_with_missing) * 100:.2f}% missing. This occurs because only 12 monthly values exist, \n",
    "and all non‚Äìmonth-end dates become NaN.\n",
    "\n",
    "2. Missing Data Patterns\n",
    "The missing data pattern is extremely structured and deterministic: missing values occur on every day except the last \n",
    "day of each month. The missing-by-month summary shows that longer months (e.g., January, March, July, August) contain \n",
    "more missing values simply because they have more non‚Äìmonth-end days. Similarly, the missing-by-weekday pattern shows \n",
    "that missing values are spread evenly across weekdays, reflecting the fact that missingness is generated by calendar \n",
    "structure rather than patient behavior or data collection issues. This pattern is typical of upsampling rather than \n",
    "real-world data gaps.\n",
    "\n",
    "Missing by month:\n",
    "{missing_by_month}\n",
    "\n",
    "Missing by day of week:\n",
    "{missing_by_day}\n",
    "\n",
    "3. Imputation Method\n",
    "I used several methods to explore different approaches to filling missing values: forward fill, backward fill, linear \n",
    "interpolation, time-based interpolation, and rolling-mean imputation. Of these, the rolling-mean imputation method \n",
    "produced the smoothest and most clinically meaningful trajectory, although it required an initial forward fill step to \n",
    "avoid propagating NaNs in long gaps.\n",
    "\n",
    "4. Rationale\n",
    "Forward fill is simple and preserves the last observed value, but it creates flat segments that may not reflect real \n",
    "physiology. Backward fill has the same issue. Linear interpolation works well for evenly spaced monthly data, but it may \n",
    "smooth too aggressively. Time-based interpolation is preferred in medical time series because it respects uneven temporal \n",
    "spacing. Rolling-mean imputation provides local smoothing and reduces noise, making it appropriate for clinical vital \n",
    "signs that tend to evolve gradually.\n",
    "\n",
    "5. Pros and Cons\n",
    "Advantages: Rolling mean reduces noise, avoids abrupt jumps, and produces realistic trends. Interpolation methods \n",
    "maintain continuity and avoid sudden step changes introduced by ffill/bfill.  \n",
    "Limitations: Rolling windows require assumptions about local smoothness, and forward fill must be used first to anchor \n",
    "the window. Interpolation may produce unrealistic values if underlying dynamics are non-linear.\n",
    "\n",
    "6. Example\n",
    "Before imputation, January had NaNs on every day except 2023-01-31. After applying rolling-mean imputation, all missing \n",
    "values were filled, resulting in a continuous daily temperature series suitable for downstream analysis.\n",
    "\"\"\"\n",
    "\n",
    "# 3. Save report\n",
    "with open('output/q2_missing_data_report.txt', 'w') as f:\n",
    "    f.write(missing_data_report)\n",
    "    f.write(\"\\n\\n--- Missing Patterns ---\\n\")\n",
    "    f.write(missing_patterns)\n",
    "\n",
    "print(\"Saved: output/q2_missing_data_report.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cf350d",
   "metadata": {},
   "source": [
    "## Submission Checklist\n",
    "\n",
    "Before moving to Question 3, verify you've created:\n",
    "\n",
    "- [ ] `output/q2_resampling_analysis.csv` - resampling analysis results\n",
    "- [ ] `output/q2_missing_data_report.txt` - missing data handling report\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
